{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "116e25e6",
   "metadata": {
    "papermill": {
     "duration": 0.004159,
     "end_time": "2025-05-31T09:37:16.745704",
     "exception": false,
     "start_time": "2025-05-31T09:37:16.741545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ce9c2f",
   "metadata": {},
   "source": [
    "This MHAF-YOLO-main is taken directly from the GiHub page of the project. https://github.com/yang-0201/MHAF-YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a14229c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T09:37:16.753604Z",
     "iopub.status.busy": "2025-05-31T09:37:16.753394Z",
     "iopub.status.idle": "2025-05-31T09:37:17.769002Z",
     "shell.execute_reply": "2025-05-31T09:37:17.767953Z"
    },
    "papermill": {
     "duration": 1.020931,
     "end_time": "2025-05-31T09:37:17.770378",
     "exception": false,
     "start_time": "2025-05-31T09:37:16.749447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/mhafyolo/pytorch/default/1/MHAF-YOLO-main /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad1d0760",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T09:37:17.778602Z",
     "iopub.status.busy": "2025-05-31T09:37:17.778293Z",
     "iopub.status.idle": "2025-05-31T09:37:17.782883Z",
     "shell.execute_reply": "2025-05-31T09:37:17.782075Z"
    },
    "papermill": {
     "duration": 0.009893,
     "end_time": "2025-05-31T09:37:17.784134",
     "exception": false,
     "start_time": "2025-05-31T09:37:17.774241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" Train Model \"\"\"\n",
    "model_yolov10 = \"/kaggle/input/byu-d-301/best.pt\"\n",
    "model_mhaf_yolo = \"/kaggle/input/mhaf-yolo-m-best/36_data_96_663.pt\"\n",
    "model_paths = [model_yolov10,model_mhaf_yolo]\n",
    "\n",
    "\n",
    "model_thresholds = [0.57, 0.52]  \n",
    "\n",
    "#MDPT\n",
    "MAX_DETECTIONS_PER_TOMO = 100\n",
    "NMS_IOU_THRESHOLD = 0.2\n",
    "CONCENTRATION = 1\n",
    "BATCH_SIZE = 8 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c4207d",
   "metadata": {
    "papermill": {
     "duration": 0.003195,
     "end_time": "2025-05-31T09:37:17.822540",
     "exception": false,
     "start_time": "2025-05-31T09:37:17.819345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **》》》 Import Libs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80a573de",
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-31T09:37:17.830000Z",
     "iopub.status.busy": "2025-05-31T09:37:17.829806Z",
     "iopub.status.idle": "2025-05-31T09:37:33.057781Z",
     "shell.execute_reply": "2025-05-31T09:37:33.057085Z"
    },
    "papermill": {
     "duration": 15.233256,
     "end_time": "2025-05-31T09:37:33.059200",
     "exception": false,
     "start_time": "2025-05-31T09:37:17.825944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this_dir: /kaggle/working\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "print(\"this_dir:\", current_dir)\n",
    "\n",
    "target_dir = Path(\"/kaggle/working/MHAF-YOLO-main\") \n",
    "os.chdir(target_dir)  \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "from ultralytics import YOLOv10\n",
    "import threading\n",
    "import time\n",
    "from contextlib import nullcontext\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a29964b",
   "metadata": {
    "papermill": {
     "duration": 0.00342,
     "end_time": "2025-05-31T09:37:33.066507",
     "exception": false,
     "start_time": "2025-05-31T09:37:33.063087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **》》》 Seed Fix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85fef1a8",
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-31T09:37:33.075993Z",
     "iopub.status.busy": "2025-05-31T09:37:33.075619Z",
     "iopub.status.idle": "2025-05-31T09:37:33.084585Z",
     "shell.execute_reply": "2025-05-31T09:37:33.083764Z"
    },
    "papermill": {
     "duration": 0.01564,
     "end_time": "2025-05-31T09:37:33.085768",
     "exception": false,
     "start_time": "2025-05-31T09:37:33.070128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x79b57fb8de30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226b9bcb",
   "metadata": {
    "papermill": {
     "duration": 0.00349,
     "end_time": "2025-05-31T09:37:33.092963",
     "exception": false,
     "start_time": "2025-05-31T09:37:33.089473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **》》》 Inference&Submission**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8201feab",
   "metadata": {
    "papermill": {
     "duration": 0.003356,
     "end_time": "2025-05-31T09:37:33.099931",
     "exception": false,
     "start_time": "2025-05-31T09:37:33.096575",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d531dfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T09:37:33.107955Z",
     "iopub.status.busy": "2025-05-31T09:37:33.107705Z",
     "iopub.status.idle": "2025-05-31T09:37:33.110842Z",
     "shell.execute_reply": "2025-05-31T09:37:33.110220Z"
    },
    "papermill": {
     "duration": 0.008442,
     "end_time": "2025-05-31T09:37:33.112008",
     "exception": false,
     "start_time": "2025-05-31T09:37:33.103566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = \"/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/\"\n",
    "test_dir = os.path.join(data_path, \"test\")\n",
    "submission_path = \"/kaggle/working/submission.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e59db5e",
   "metadata": {
    "papermill": {
     "duration": 0.003489,
     "end_time": "2025-05-31T09:37:33.119141",
     "exception": false,
     "start_time": "2025-05-31T09:37:33.115652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* GPU Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e00d8be3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T09:37:33.127432Z",
     "iopub.status.busy": "2025-05-31T09:37:33.127173Z",
     "iopub.status.idle": "2025-05-31T09:37:33.209131Z",
     "shell.execute_reply": "2025-05-31T09:37:33.208396Z"
    },
    "papermill": {
     "duration": 0.08758,
     "end_time": "2025-05-31T09:37:33.210419",
     "exception": false,
     "start_time": "2025-05-31T09:37:33.122839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: Tesla P100-PCIE-16GB with 17.06 GB memory\n",
      "Dynamic batch size set to 32 based on 17.06GB free memory\n"
     ]
    }
   ],
   "source": [
    "class GPUProfiler:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.start_time = None\n",
    "        \n",
    "    def __enter__(self):\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        self.start_time = time.time()\n",
    "        return self\n",
    "        \n",
    "    def __exit__(self, *args):\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        elapsed = time.time() - self.start_time\n",
    "        # print(f\"[PROFILE] {self.name}: {elapsed:.3f}s\")\n",
    "\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "if device.startswith('cuda'):\n",
    "    # Set CUDA optimization flags\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True  # Allow TF32 on Ampere GPUs\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    \n",
    "    # Print GPU info\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9  # Convert to GB\n",
    "    print(f\"Using GPU: {gpu_name} with {gpu_mem:.2f} GB memory\")\n",
    "    \n",
    "    # Get available GPU memory and set batch size accordingly\n",
    "    free_mem = gpu_mem - torch.cuda.memory_allocated(0) / 1e9\n",
    "    BATCH_SIZE = max(8, min(32, int(free_mem * 4)))  # 4 images per GB as rough estimate\n",
    "    print(f\"Dynamic batch size set to {BATCH_SIZE} based on {free_mem:.2f}GB free memory\")\n",
    "else:\n",
    "    print(\"GPU not available, using CPU\")\n",
    "    BATCH_SIZE = 4  # Reduce batch size for CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f76edd8",
   "metadata": {
    "papermill": {
     "duration": 0.00351,
     "end_time": "2025-05-31T09:37:33.217713",
     "exception": false,
     "start_time": "2025-05-31T09:37:33.214203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c6dfdc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T09:37:33.225612Z",
     "iopub.status.busy": "2025-05-31T09:37:33.225396Z",
     "iopub.status.idle": "2025-05-31T09:37:33.231645Z",
     "shell.execute_reply": "2025-05-31T09:37:33.230940Z"
    },
    "papermill": {
     "duration": 0.011553,
     "end_time": "2025-05-31T09:37:33.232839",
     "exception": false,
     "start_time": "2025-05-31T09:37:33.221286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_slice(slice_data):\n",
    "    \"\"\"\n",
    "    Normalize slice data using 2nd and 98th percentiles for better contrast\n",
    "    \"\"\"\n",
    "    p2 = np.percentile(slice_data, 2)\n",
    "    p98 = np.percentile(slice_data, 98)\n",
    "    clipped_data = np.clip(slice_data, p2, p98)\n",
    "    normalized = 255 * (clipped_data - p2) / (p98 - p2)\n",
    "    return np.uint8(normalized)\n",
    "\n",
    "def preload_image_batch(file_paths):\n",
    "    \"\"\"Preload a batch of images to CPU memory\"\"\"\n",
    "    images = []\n",
    "    for path in file_paths:\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            # Try with PIL as fallback\n",
    "            img = np.array(Image.open(path))\n",
    "        images.append(img)\n",
    "    return images\n",
    "\n",
    "def perform_3d_nms(detections, iou_threshold):\n",
    "    \"\"\"\n",
    "    Perform 3D Non-Maximum Suppression on detections to merge nearby motors\n",
    "    \"\"\"\n",
    "    if not detections:\n",
    "        return []\n",
    "\n",
    "    # Sort by confidence (highest first)\n",
    "    detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)\n",
    "\n",
    "    # List to store final detections after NMS\n",
    "    final_detections = []\n",
    "\n",
    "    # Define 3D distance function\n",
    "    def distance_3d(d1, d2):\n",
    "        return np.sqrt((d1['z'] - d2['z'])**2 +\n",
    "                       (d1['y'] - d2['y'])**2 +\n",
    "                       (d1['x'] - d2['x'])**2)\n",
    "\n",
    "    # Maximum distance threshold (based on box size and slice gap)\n",
    "    box_size = 24  # Same as annotation box size\n",
    "    distance_threshold = box_size * iou_threshold\n",
    "\n",
    "    # Process each detection\n",
    "    while detections:\n",
    "        # Take the detection with highest confidence\n",
    "        best_detection = detections.pop(0)\n",
    "        final_detections.append(best_detection)\n",
    "\n",
    "        # Filter out detections that are too close to the best detection\n",
    "        detections = [d for d in detections if distance_3d(d, best_detection) > distance_threshold]\n",
    "\n",
    "    return final_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cebcb26",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-31T09:37:33.240943Z",
     "iopub.status.busy": "2025-05-31T09:37:33.240744Z",
     "iopub.status.idle": "2025-05-31T09:37:34.569159Z",
     "shell.execute_reply": "2025-05-31T09:37:34.568436Z"
    },
    "papermill": {
     "duration": 1.334221,
     "end_time": "2025-05-31T09:37:34.570794",
     "exception": false,
     "start_time": "2025-05-31T09:37:33.236573",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_tomogram(tomo_id, models, index=0, total=1):\n",
    "    \"\"\"\n",
    "    Process a single tomogram using multiple YOLO models for ensemble inference.\n",
    "    Returns the most confident motor detection based on weighted averaging.\n",
    "    \"\"\"\n",
    "    tomo_dir = os.path.join(test_dir, tomo_id)\n",
    "    slice_files = sorted([f for f in os.listdir(tomo_dir) if f.endswith('.jpg')])\n",
    "\n",
    "    selected_indices = np.linspace(0, len(slice_files)-1, int(len(slice_files) * CONCENTRATION))\n",
    "    selected_indices = np.round(selected_indices).astype(int)\n",
    "    slice_files = [slice_files[i] for i in selected_indices]\n",
    "\n",
    "    all_detections = []\n",
    "\n",
    "    if device.startswith('cuda'):\n",
    "        streams = [torch.cuda.Stream() for _ in range(min(4, BATCH_SIZE))]\n",
    "    else:\n",
    "        streams = [None]\n",
    "\n",
    "    next_batch_thread = None\n",
    "    next_batch_images = None\n",
    "\n",
    "    for batch_start in range(0, len(slice_files), BATCH_SIZE):\n",
    "        if next_batch_thread is not None:\n",
    "            next_batch_thread.join()\n",
    "            next_batch_images = None\n",
    "\n",
    "        batch_end = min(batch_start + BATCH_SIZE, len(slice_files))\n",
    "        batch_files = slice_files[batch_start:batch_end]\n",
    "\n",
    "        next_batch_start = batch_end\n",
    "        next_batch_end = min(next_batch_start + BATCH_SIZE, len(slice_files))\n",
    "        next_batch_files = slice_files[next_batch_start:next_batch_end] if next_batch_start < len(slice_files) else []\n",
    "\n",
    "        if next_batch_files:\n",
    "            next_batch_paths = [os.path.join(tomo_dir, f) for f in next_batch_files]\n",
    "            next_batch_thread = threading.Thread(target=preload_image_batch, args=(next_batch_paths,))\n",
    "            next_batch_thread.start()\n",
    "        else:\n",
    "            next_batch_thread = None\n",
    "\n",
    "        sub_batches = np.array_split(batch_files, len(streams))\n",
    "        sub_batch_results = []\n",
    "\n",
    "        for i, sub_batch in enumerate(sub_batches):\n",
    "            if len(sub_batch) == 0:\n",
    "                continue\n",
    "\n",
    "            stream = streams[i % len(streams)]\n",
    "            with torch.cuda.stream(stream) if stream and device.startswith('cuda') else nullcontext():\n",
    "                sub_batch_paths = [os.path.join(tomo_dir, slice_file) for slice_file in sub_batch]\n",
    "                sub_batch_slice_nums = [int(slice_file.split('_')[1].split('.')[0]) for slice_file in sub_batch]\n",
    "\n",
    "                ensemble_predictions = []\n",
    "\n",
    "                for model_idx, model in enumerate(models):\n",
    "                    # Use model-specific threshold\n",
    "                    model_threshold = model_thresholds[model_idx]\n",
    "                    \n",
    "                    with GPUProfiler(f\"Inference batch {i+1}/{len(sub_batches)}\"):\n",
    "                        sub_results = model(sub_batch_paths, verbose=False)\n",
    "\n",
    "                    for j, result in enumerate(sub_results):\n",
    "                        if len(result.boxes) > 0:\n",
    "                            boxes = result.boxes\n",
    "                            for box_idx, confidence in enumerate(boxes.conf):\n",
    "                                if confidence >= model_threshold:  # Use model-specific threshold\n",
    "                                    x1, y1, x2, y2 = boxes.xyxy[box_idx].cpu().numpy()\n",
    "                                    x_center = (x1 + x2) / 2\n",
    "                                    y_center = (y1 + y2) / 2\n",
    "\n",
    "                                    ensemble_predictions.append({\n",
    "                                        'z': round(sub_batch_slice_nums[j]),\n",
    "                                        'y': round(y_center),\n",
    "                                        'x': round(x_center),\n",
    "                                        'confidence': float(confidence),\n",
    "                                        'model_idx': model_idx  # Optionally track which model made the detection\n",
    "                                    })\n",
    "\n",
    "                # Fusion of ensemble predictions (Weighted Averaging)\n",
    "                fused_detections = fuse_ensemble_detections(ensemble_predictions)\n",
    "                all_detections.extend(fused_detections)\n",
    "\n",
    "        if device.startswith('cuda'):\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "    if next_batch_thread is not None:\n",
    "        next_batch_thread.join()\n",
    "\n",
    "    final_detections = perform_3d_nms(all_detections, NMS_IOU_THRESHOLD)\n",
    "    final_detections.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "\n",
    "    if not final_detections:\n",
    "        return {'tomo_id': tomo_id, 'Motor axis 0': -1, 'Motor axis 1': -1, 'Motor axis 2': -1}\n",
    "\n",
    "    best_detection = final_detections[0]\n",
    "\n",
    "    return {\n",
    "        'tomo_id': tomo_id,\n",
    "        'Motor axis 0': round(best_detection['z']),\n",
    "        'Motor axis 1': round(best_detection['y']),\n",
    "        'Motor axis 2': round(best_detection['x'])\n",
    "    }\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "def fuse_ensemble_detections(detections, eps=10, min_samples=2):\n",
    "    \"\"\"\n",
    "    Fuse detections using DBSCAN clustering on (z, y, x) coordinates.\n",
    "    Each cluster is merged via confidence-weighted averaging.\n",
    "    \n",
    "    Parameters:\n",
    "    - detections: list of dicts with keys ['z', 'y', 'x', 'confidence']\n",
    "    - eps: max distance (in voxel units) to cluster\n",
    "    - min_samples: minimum number of detections to form a cluster\n",
    "    \"\"\"\n",
    "    if not detections:\n",
    "        return []\n",
    "\n",
    "    coords = np.array([[d['z'], d['y'], d['x']] for d in detections])\n",
    "    confidences = np.array([d['confidence'] for d in detections])\n",
    "\n",
    "    # Run DBSCAN clustering\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples, n_jobs=-1).fit(coords)\n",
    "    labels = clustering.labels_\n",
    "\n",
    "    final_detections = []\n",
    "    unique_labels = set(labels)\n",
    "\n",
    "    for label in unique_labels:\n",
    "        if label == -1:\n",
    "            continue  # Skip noise\n",
    "\n",
    "        indices = np.where(labels == label)[0]\n",
    "        cluster_dets = [detections[i] for i in indices]\n",
    "        cluster_confs = confidences[indices]\n",
    "        total_conf = np.sum(cluster_confs)\n",
    "\n",
    "        weighted_z = np.sum([d['z'] * d['confidence'] for d in cluster_dets]) / total_conf\n",
    "        weighted_y = np.sum([d['y'] * d['confidence'] for d in cluster_dets]) / total_conf\n",
    "        weighted_x = np.sum([d['x'] * d['confidence'] for d in cluster_dets]) / total_conf\n",
    "        avg_conf = total_conf / len(cluster_dets)\n",
    "\n",
    "        final_detections.append({\n",
    "            'z': round(weighted_z),\n",
    "            'y': round(weighted_y),\n",
    "            'x': round(weighted_x),\n",
    "            'confidence': avg_conf\n",
    "        })\n",
    "\n",
    "    return final_detections\n",
    "\n",
    "def generate_submission():\n",
    "    \"\"\"\n",
    "    Generate submission file using ensemble models.\n",
    "    \"\"\"\n",
    "    test_tomos = sorted([d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d))])\n",
    "    total_tomos = len(test_tomos)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    models = [YOLOv10(path).to(device) for path in model_paths]\n",
    "\n",
    "    if device.startswith('cuda'):\n",
    "        for model in models:\n",
    "            model.fuse()\n",
    "            if torch.cuda.get_device_capability(0)[0] >= 7:\n",
    "                model.model.half()\n",
    "\n",
    "    results = []\n",
    "    motors_found = 0\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        future_to_tomo = {}\n",
    "\n",
    "        for i, tomo_id in enumerate(test_tomos, 1):\n",
    "            future = executor.submit(process_tomogram, tomo_id, models, i, total_tomos)\n",
    "            future_to_tomo[future] = tomo_id\n",
    "\n",
    "        for future in future_to_tomo:\n",
    "            tomo_id = future_to_tomo[future]\n",
    "            try:\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "\n",
    "                if result['Motor axis 0'] != -1:\n",
    "                    motors_found += 1\n",
    "                    print(f\"Motor found in {tomo_id} at z={result['Motor axis 0']}, y={result['Motor axis 1']}, x={result['Motor axis 2']}\")\n",
    "                else:\n",
    "                    print(f\"No motor detected in {tomo_id}\")\n",
    "\n",
    "                print(f\"Detection rate: {motors_found}/{len(results)} ({motors_found/len(results)*100:.1f}%)\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {tomo_id}: {e}\")\n",
    "                results.append({'tomo_id': tomo_id, 'Motor axis 0': -1, 'Motor axis 1': -1, 'Motor axis 2': -1})\n",
    "\n",
    "    submission_df = pd.DataFrame(results)\n",
    "    submission_df = submission_df[['tomo_id', 'Motor axis 0', 'Motor axis 1', 'Motor axis 2']]\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "    print(\"= Submission Preview:\")\n",
    "    print(submission_df.head())\n",
    "\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc436f7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T09:37:34.579644Z",
     "iopub.status.busy": "2025-05-31T09:37:34.579224Z",
     "iopub.status.idle": "2025-05-31T09:41:04.944237Z",
     "shell.execute_reply": "2025-05-31T09:41:04.943065Z"
    },
    "papermill": {
     "duration": 210.370947,
     "end_time": "2025-05-31T09:41:04.945812",
     "exception": false,
     "start_time": "2025-05-31T09:37:34.574865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/MHAF-YOLO-main/ultralytics/nn/tasks.py:751: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv10x summary (fused): 503 layers, 31586006 parameters, 0 gradients\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "MAF-YOLOv10m-v2 summary: 838 layers, 15799254 parameters, 824896 gradients\n",
      "YOLOv10x summary (fused): 503 layers, 31586006 parameters, 0 gradients\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "Switch model to UniRepLKNetBlock\n",
      "No motor detected in tomo_003acc\n",
      "Detection rate: 0/1 (0.0%)\n",
      "Motor found in tomo_00e047 at z=171, y=546, x=603\n",
      "Detection rate: 1/2 (50.0%)\n",
      "Motor found in tomo_01a877 at z=139, y=638, x=288\n",
      "Detection rate: 2/3 (66.7%)\n",
      "= Submission Preview:\n",
      "       tomo_id  Motor axis 0  Motor axis 1  Motor axis 2\n",
      "0  tomo_003acc            -1            -1            -1\n",
      "1  tomo_00e047           171           546           603\n",
      "2  tomo_01a877           139           638           288\n",
      "(3, 4)\n",
      "\n",
      "Total execution time: 210.36 seconds (3.51 minutes)\n"
     ]
    }
   ],
   "source": [
    "# Run the submission pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    # Time entire process\n",
    "    start_time = time.time()\n",
    "    # Generate submission\n",
    "    submission = generate_submission()\n",
    "    print(submission.shape)\n",
    "    # Print total execution time\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\nTotal execution time: {elapsed:.2f} seconds ({elapsed/60:.2f} minutes)\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11294684,
     "sourceId": 91249,
     "sourceType": "competition"
    },
    {
     "datasetId": 6880023,
     "sourceId": 11044741,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6989638,
     "sourceId": 11195676,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7441953,
     "sourceId": 11933973,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 227202990,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 295634,
     "modelInstanceId": 274744,
     "sourceId": 327336,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 232.741231,
   "end_time": "2025-05-31T09:41:06.877538",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-31T09:37:14.136307",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
